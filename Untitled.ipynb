{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from pytorch_transformers import BertModel, BertConfig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert = BertModel.from_pretrained('bert-base-uncased', cache_dir='./')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from backbone.model_builder import BertSeparator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "bertsep_weight = torch.load('models/model_step_10000.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0192,  0.0265, -0.0274,  ...,  0.0137,  0.0799,  0.0568],\n",
       "        [-0.0343,  0.0383, -0.0433,  ..., -0.0492,  0.1376,  0.0095],\n",
       "        [ 0.0128,  0.0319,  0.0114,  ..., -0.0279,  0.0268, -0.0462],\n",
       "        ...,\n",
       "        [-0.0099,  0.0506,  0.0580,  ...,  0.0262,  0.0548, -0.0524],\n",
       "        [-0.0204,  0.0928,  0.0593,  ..., -0.1053,  0.0598,  0.0458],\n",
       "        [ 0.0004, -0.0958,  0.0111,  ..., -0.0208, -0.0512, -0.0056]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bertsep_weight['model']['bert.model.encoder.layer.0.attention.self.query.weight']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0164,  0.0261, -0.0263,  ...,  0.0154,  0.0768,  0.0548],\n",
       "        [-0.0326,  0.0346, -0.0423,  ..., -0.0527,  0.1393,  0.0078],\n",
       "        [ 0.0105,  0.0334,  0.0109,  ..., -0.0279,  0.0258, -0.0468],\n",
       "        ...,\n",
       "        [-0.0085,  0.0514,  0.0555,  ...,  0.0282,  0.0543, -0.0541],\n",
       "        [-0.0198,  0.0944,  0.0617,  ..., -0.1042,  0.0601,  0.0470],\n",
       "        [ 0.0015, -0.0952,  0.0099,  ..., -0.0191, -0.0508, -0.0085]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert.state_dict()['encoder.layer.0.attention.self.query.weight']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "bertsum_weight = torch.load('models/bertsum_model_best.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0191,  0.0264, -0.0272,  ...,  0.0137,  0.0795,  0.0567],\n",
       "        [-0.0340,  0.0385, -0.0424,  ..., -0.0492,  0.1378,  0.0094],\n",
       "        [ 0.0131,  0.0319,  0.0112,  ..., -0.0275,  0.0271, -0.0459],\n",
       "        ...,\n",
       "        [-0.0096,  0.0507,  0.0582,  ...,  0.0263,  0.0548, -0.0521],\n",
       "        [-0.0206,  0.0928,  0.0593,  ..., -0.1052,  0.0594,  0.0457],\n",
       "        [ 0.0003, -0.0956,  0.0107,  ..., -0.0209, -0.0516, -0.0062]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bertsum_weight['model']['bert.model.encoder.layer.0.attention.self.query.weight']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from easydict import EasyDict\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from pytorch_transformers import BertModel, BertConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = EasyDict({\n",
    "    \"visible_gpus\" : -1,\n",
    "    \"temp_dir\" : './tmp/',\n",
    "    \"test_from\": None,\n",
    "    \"max_pos\" : 512,\n",
    "    \"large\" : False,\n",
    "    \"finetune_bert\": True,\n",
    "    \"encoder\": \"bert\",\n",
    "    \"share_emb\": False,\n",
    "    \"dec_layers\": 6,\n",
    "    \"dec_dropout\": 0.2,\n",
    "    \"dec_hidden_size\": 768,\n",
    "    \"dec_heads\": 8,\n",
    "    \"dec_ff_size\": 2048,\n",
    "    \"enc_hidden_size\": 512,\n",
    "    \"enc_ff_size\": 512,\n",
    "    \"enc_dropout\": 0.2,\n",
    "    \"enc_layers\": 6,\n",
    "    \n",
    "    \"ext_dropout\": 0.2,\n",
    "    \"ext_layers\": 2,\n",
    "    \"ext_hidden_size\": 768,\n",
    "    \"ext_heads\": 8,\n",
    "    \"ext_ff_size\": 2048,\n",
    "    \n",
    "    \"accum_count\": 1,\n",
    "    \"save_checkpoint_steps\": 5,\n",
    "    \n",
    "    \"generator_shard_size\": 32,\n",
    "    \"alpha\": 0.6,\n",
    "    \"beam_size\": 5,\n",
    "    \"min_length\": 15,\n",
    "    \"max_length\": 150,\n",
    "    \"max_tgt_len\": 140,  \n",
    "    \"block_trigram\": True,\n",
    "    \n",
    "    \"model_path\": \"./tmp_model/\",\n",
    "    \"result_path\": \"./tmp_result/src\",\n",
    "    \"recall_eval\": False,\n",
    "    \"report_every\": 1,\n",
    "    \n",
    "    \"window_size\": 3,\n",
    "    \"backbone_type\": 'bertsum',\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.data_loader import TextLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "testset = torch.load('dataset/cnndm/bert_data/test_articles.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "text = testset[0]['src_txt'][:7] + testset[1]['src_txt'][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "textloader = TextLoader(args, 'cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "source = ['\\n'.join(text[:6]), '\\n'.join(text[1:7]), '\\n'.join(text[2:8])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = textloader.load_text(source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in texts:\n",
    "    b = batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "(src, segs, clss, mask_src, mask_cls), src_txt = b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  101,  1047, 23393, 12377,  2072, 14891, 27760,  5422,  1996,  3842,\n",
       "          1010,  2119,  2010,  6793,  1998,  3652,  7892,  1010,  2000,  2954,\n",
       "          2114,  1996,  4099,  1012,   102,   101,  2002,  7944,  2041,  1996,\n",
       "          2162,  2005,  2809,  2086,  1010,  2750, 24111,  1005,  2015, 19732,\n",
       "          2000,  5138,  1037, 26277,  1010,  1998,  2947, 27697,  1996, 10100,\n",
       "          1997,  1996,  5499,  3072,  1012,   102,   101,  2011,  1996,  2051,\n",
       "          2002,  3092,  1996,  2162,  1010,  1996,  4610,  2001,  1999, 25850,\n",
       "         13510,  1010,  1998,  2045,  2001,  2053,  3696,  1997,  2010,  3280,\n",
       "         29624, 11783,  7314,  1012,   102,   101,  2144,  2059,  1010,  1000,\n",
       "          5948,  1037, 15775, 13231,  1997,  9947,  1000,  2038,  2150,  2112,\n",
       "          1997,  7726,  2576, 16105,  8663,  1010,  1998,  2116, 18288,  2031,\n",
       "          2356,  3251,  1037, 26139, 14511,  4430,  4862,  1047,  3511,  8625,\n",
       "          2072,  1010,  1047, 23393, 12377,  2072,  1005,  2015,  6332,  1010,\n",
       "          2052,  5333,  1996, 15775, 13231,  1998,  7806,  2000,  7670,  2011,\n",
       "          1996,  2225,  2000,  2203,  4238,  1005,  2015,  4517,  2565,  1012,\n",
       "           102,   101,  2066,  1996,  2162,  1010,  4238,  1005,  2015, 19674,\n",
       "          2000,  9190,  2049,  6801,  4517,  2565,  2038,  4225,  1047,  3511,\n",
       "         18595,  1005,  2015,  3690,  1012,   102,   101,  2044,  2176,  2086,\n",
       "         26472,  1996,  7541,  4774,  2000,  2256,  3103,  1010,  1996, 11981,\n",
       "         12076,  2097,  2023,  2733,  2191,  1037,  2331, 29624,  4305,  3726,\n",
       "          2046,  8714,   102]], device='cuda:0')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['khomeini galvanized the nation , both his supporters and growing opponents , to fight against the enemy .',\n",
       " \"he dragged out the war for eight years , despite saddam 's willingness to accept a ceasefire , and thus stabilized the foundations of the islamic republic .\",\n",
       " 'by the time he ended the war , the economy was in shambles , and there was no sign of his die-hard volunteers .',\n",
       " 'since then , \" drinking a chalice of poison \" has became part of iranian political lexicon , and many analysts have asked whether ayatollah ali khamenei , khomeini \\'s successor , would raise the chalice and surrender to demands by the west to end iran \\'s nuclear program .',\n",
       " \"like the war , iran 's defiance to halt its controversial nuclear program has defined khameni 's era .\",\n",
       " 'after four years orbiting the closest planet to our sun , the messenger spacecraft will this week make a death-dive into mercury .']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src_txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('test_text.txt', 'a') as f:\n",
    "    f.write('\\n'.join(src_txt))\n",
    "    f.write('\\n'*4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.038369153702902614"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.random()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'00000'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'00'.zfill(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = ['aaa', 'bbb', 'ccc', 'ddd', 'eee', 'fff']\n",
    "B = [0, 0, 1, 1, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = [0] * (len(A) + len(B))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "C[::2] = A\n",
    "C[1::2] = B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['aaa', 0, 'bbb', 0, 'ccc', 1, 'ddd', 1, 'eee', 1, 'fff']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1.0', '2.0', '3.0']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "list(map(str, np.array([1, 2, 3.0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "452f9cde2172c13f72b4db7ce0e0469a2256496cbf613033eae53207fccfcf38"
  },
  "kernelspec": {
   "display_name": "subtext",
   "language": "python",
   "name": "subtext"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
